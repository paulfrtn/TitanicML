{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult Income Exercise\n",
    "\n",
    "For this exercise we will use a dataset that contains some features about people and we need to predict <b>if each person is payed more than 50.000 $ annualy or not</b>.\n",
    "\n",
    "- You need to:\n",
    "    - Explore the dataset\n",
    "    - Give some basic information about the data\n",
    "    - Preprocess the data (missing values, imputation...)\n",
    "    - Test various Machine Learning algorithms\n",
    "    - Evaluate the performance of these algorithms over the test data in terms of Accuracy, Precision, Recall, F1, plot the confusion matrix...\n",
    "    - Chose one of these algorithms to perfom the task prediction and explain why (in comments or in a markdown cell)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de NaN dans X_train :  0\n",
      "Nombre de NaN dans X_test :  87\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Submission file created: result.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Lire les données\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_train.replace('', pd.NA, inplace=True)\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "X_train = df_train.drop(columns=[\"Survived\"], axis=1)\n",
    "X_test = pd.read_csv('data/test.csv')\n",
    "y_train = df_train[\"Survived\"]\n",
    "\n",
    "# Sauvegarde de la colonne PassengerId avant transformations\n",
    "X_test_passenger_id = X_test[\"PassengerId\"].copy()\n",
    "\n",
    "# Sélection des colonnes numériques\n",
    "numeric_columns = X_train.dtypes[((X_train.dtypes==\"float64\") | (X_train.dtypes==\"int64\"))].index.values.tolist()\n",
    "\n",
    "# Sélection des colonnes catégorielles\n",
    "categorical_col = X_train.dtypes[X_train.dtypes==\"object\"].index.values.tolist()\n",
    "\n",
    "# Standardisation des colonnes numériques\n",
    "mmc = StandardScaler()\n",
    "X_train[numeric_columns] = mmc.fit_transform(X_train[numeric_columns])\n",
    "X_test[numeric_columns] = mmc.transform(X_test[numeric_columns])\n",
    "\n",
    "# Encodage des colonnes catégorielles\n",
    "ohe = OneHotEncoder(drop=None, handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "ohe_cols = [col for col in categorical_col if col in X_test.columns]\n",
    "\n",
    "X_train_encoded = pd.DataFrame(ohe.fit_transform(X_train[ohe_cols]), index=X_train.index)\n",
    "X_test_encoded = pd.DataFrame(ohe.transform(X_test[ohe_cols]), index=X_test.index)\n",
    "\n",
    "X_train_encoded.columns = ohe.get_feature_names_out(ohe_cols)\n",
    "X_test_encoded.columns = ohe.get_feature_names_out(ohe_cols)\n",
    "\n",
    "X_train.drop(ohe_cols, axis=1, inplace=True)\n",
    "X_test.drop(ohe_cols, axis=1, inplace=True)\n",
    "\n",
    "X_train = pd.concat([X_train, X_train_encoded], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_encoded], axis=1)\n",
    "\n",
    "# Vérification des NaN après transformation\n",
    "print(\"Nombre de NaN dans X_train : \", X_train.isna().sum().sum())\n",
    "print(\"Nombre de NaN dans X_test : \", X_test.isna().sum().sum())\n",
    "\n",
    "# Remplacer les NaN par la moyenne des colonnes\n",
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "X_test.fillna(X_test.mean(), inplace=True)\n",
    "\n",
    "# Gradient Boosting avec RandomizedSearchCV\n",
    "random_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [int(x) for x in np.linspace(10, 110, num=11)] + [None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'learning_rate': [0.1, 1],\n",
    "    'subsample': [0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=0)\n",
    "gb_search = RandomizedSearchCV(estimator=gb, param_distributions=random_grid, n_iter=10, cv=3, verbose=1, random_state=0)\n",
    "gb_search.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur le jeu de test\n",
    "y_test_pred = gb_search.predict(X_test)\n",
    "\n",
    "# Utiliser la colonne PassengerId sauvegardée\n",
    "result = pd.concat([X_test_passenger_id, pd.DataFrame(y_test_pred)], axis=1)\n",
    "result.columns = [\"PassengerId\", \"Survived\"]\n",
    "\n",
    "# Convertir PassengerId en entier (au cas où)\n",
    "result[\"PassengerId\"] = result[\"PassengerId\"].astype(int)\n",
    "\n",
    "# Création du fichier de soumission pour Kaggle\n",
    "result.to_csv(\"result.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chose one of the algorithms and explain why\n",
    "\n",
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après analyse de l'accuracy et des valeurs f1 score, on en conclut que l'algorithme le plus performant est le gradient boosting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
