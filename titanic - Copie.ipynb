{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Meilleurs paramètres :  {'n_estimators': 300, 'min_weight_fraction_leaf': 0.0, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_depth': 80, 'criterion': 'entropy', 'class_weight': 'balanced', 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn import metrics\n",
    "import bisect\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/train.csv')\n",
    "\n",
    "X_train = df.drop(columns=[\"Survived\"], axis=1)\n",
    "X_test = pd.read_csv('data/test.csv')\n",
    "y_train = df[\"Survived\"]\n",
    "# Supprimer les lignes contenant un '?'\n",
    "\n",
    "# fnlwgt is a weight variable that represents the demographic characteristics of each person surveyed.\n",
    "df.head()\n",
    "df.shape\n",
    "df.describe()\n",
    "df.isna().sum()\n",
    "# Ajouter un titre et des Ã©tiquettes\n",
    "X_test_passenger_id = X_test[\"PassengerId\"].copy()\n",
    "\n",
    "\n",
    "\n",
    "# Utiliser la colonne PassengerId sauvegardée\n",
    "\n",
    "\n",
    "numeric_columns = df.dtypes[((df.dtypes==\"float64\")|(df.dtypes==\"int64\"))].index.values.tolist()\n",
    "\n",
    "\n",
    "    \n",
    "categorical_col = df.dtypes[df.dtypes==\"object\"].index.values.tolist()\n",
    "\n",
    "\n",
    "mmc = StandardScaler()\n",
    "\n",
    "scaled_columns = [x for x in numeric_columns if x != 'Survived']\n",
    "print(numeric_columns)\n",
    "\n",
    "X_train[scaled_columns] = mmc.fit_transform(X_train[scaled_columns])\n",
    "X_test[scaled_columns] = mmc.transform(X_test[scaled_columns])\n",
    "\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder(drop = None, handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "ohe_cols = [col for col in categorical_col if col in X_test.columns]\n",
    "\n",
    "\n",
    "X_train_encoded = pd.DataFrame(ohe.fit_transform(X_train[ohe_cols]), index=X_train.index)\n",
    "X_test_encoded = pd.DataFrame(ohe.transform(X_test[ohe_cols]), index=X_test.index)\n",
    "\n",
    "X_train_encoded.columns = ohe.get_feature_names_out(ohe_cols)\n",
    "X_test_encoded.columns = ohe.get_feature_names_out(ohe_cols)\n",
    "\n",
    "X_train.drop(ohe_cols ,axis=1, inplace=True)\n",
    "X_test.drop(ohe_cols ,axis=1, inplace=True)\n",
    "\n",
    "X_train = pd.concat([X_train, X_train_encoded], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_encoded ], axis=1)\n",
    "\n",
    "# Définir le grille de paramètres pour Random Forest\n",
    "random_grid = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=50, stop=400, num=8)],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [int(x) for x in np.linspace(10, 110, num=11)] + [None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'class_weight': [None, 'balanced'],  \n",
    "    'max_leaf_nodes': [None] + [int(x) for x in np.linspace(10, 100, num=10)],  \n",
    "    'min_weight_fraction_leaf': [0.0, 0.1],  \n",
    "    'criterion': ['gini', 'entropy'] \n",
    "}\n",
    "\n",
    "# Rechercher les meilleurs paramètres\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf_search = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=10, cv=3, verbose=1, random_state=0)\n",
    "rf_search.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_test_pred = rf_search.predict(X_test)\n",
    "\n",
    "# Afficher les meilleurs paramètres\n",
    "print(\"Meilleurs paramètres : \", rf_search.best_params_)\n",
    "\n",
    "# Créer un DataFrame pour les résultats\n",
    "result = pd.concat([X_test_passenger_id, pd.DataFrame(y_test_pred)], axis=1)\n",
    "result.columns = [\"PassengerId\", \"Survived\"]\n",
    "result[\"PassengerId\"] = result[\"PassengerId\"].astype(int)\n",
    "result.to_csv(\"result.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
