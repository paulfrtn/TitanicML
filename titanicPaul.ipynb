{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T09:34:52.072262Z",
     "start_time": "2024-10-23T09:34:24.531986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Lecture de données\n",
    "df_train = pd.read_csv(\"./data/train.csv\")\n",
    "df_test = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "# Vérification des données\n",
    "print(\"Train Dataset Shape:\", df_train.shape)\n",
    "print(\"Test Dataset Shape:\", df_test.shape)\n",
    "\n",
    "# Gestion des valeurs manquantes\n",
    "# Remplacer les valeurs manquantes dans 'Age' par la médiane\n",
    "df_train['Age'].fillna(df_train['Age'].median(), inplace=True)\n",
    "df_test['Age'].fillna(df_test['Age'].median(), inplace=True)\n",
    "\n",
    "# Remplacer les valeurs manquantes dans 'Embarked' par la valeur la plus fréquente\n",
    "df_train['Embarked'].fillna(df_train['Embarked'].mode()[0], inplace=True)\n",
    "df_test['Embarked'].fillna(df_test['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Remplacer les valeurs manquantes dans 'Fare' (test set uniquement) par la médiane\n",
    "df_test['Fare'].fillna(df_test['Fare'].median(), inplace=True)\n",
    "\n",
    "# Colonnes à supprimer car inutiles pour la modélisation\n",
    "df_train.drop(['Cabin', 'Ticket', 'Name'], axis=1, inplace=True)\n",
    "df_test.drop(['Cabin', 'Ticket', 'Name'], axis=1, inplace=True)\n",
    "\n",
    "# Assurer que les colonnes 'Sex' et 'Embarked' sont bien de type string\n",
    "df_train['Sex'] = df_train['Sex'].astype(str)\n",
    "df_train['Embarked'] = df_train['Embarked'].astype(str)\n",
    "df_test['Sex'] = df_test['Sex'].astype(str)\n",
    "df_test['Embarked'] = df_test['Embarked'].astype(str)\n",
    "\n",
    "# Vérifier les valeurs manquantes dans ces colonnes\n",
    "print(df_train[['Sex', 'Embarked']].isnull().sum())\n",
    "print(df_test[['Sex', 'Embarked']].isnull().sum())\n",
    "\n",
    "# Encodage des variables catégorielles\n",
    "label_encoder_sex = LabelEncoder()\n",
    "label_encoder_embarked = LabelEncoder()\n",
    "\n",
    "# Encoder 'Sex' et 'Embarked' pour les deux jeux de données\n",
    "df_train['Sex'] = label_encoder_sex.fit_transform(df_train['Sex'])\n",
    "df_train['Embarked'] = label_encoder_embarked.fit_transform(df_train['Embarked'])\n",
    "df_test['Sex'] = label_encoder_sex.transform(df_test['Sex'])\n",
    "df_test['Embarked'] = label_encoder_embarked.transform(df_test['Embarked'])\n",
    "\n",
    "# Séparation des features (X) et de la cible (Y)\n",
    "X = df_train.drop('Survived', axis=1)  # Enlever la colonne cible pour X\n",
    "Y = df_train['Survived']  # La colonne cible\n",
    "\n",
    "# Division des données en jeu d'entraînement et de test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vérifier la taille des jeux de données\n",
    "print(\"Taille de X_train :\", X_train.shape)\n",
    "print(\"Taille de X_test :\", X_test.shape)\n",
    "print(\"Taille de Y_train :\", Y_train.shape)\n",
    "print(\"Taille de Y_test :\", Y_test.shape)\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Modèle de Gradient Boosting\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "grid_search_gb = GridSearchCV(estimator=gradient_boosting, param_grid=param_grid_gb,\n",
    "                              cv=5, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Entraîner le modèle\n",
    "grid_search_gb.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Meilleur modèle\n",
    "best_gradient_boosting = grid_search_gb.best_estimator_\n",
    "\n",
    "# Prédiction sur le jeu de test\n",
    "Y_pred_gb = best_gradient_boosting.predict(X_test_scaled)\n",
    "\n",
    "# Calculer le score F1\n",
    "f1_score_gb = metrics.f1_score(Y_test, Y_pred_gb, average='macro')\n",
    "print(f'Macro F1 Score (Gradient Boosting): {f1_score_gb}')\n"
   ],
   "id": "fceee52c2373b0db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Shape: (891, 12)\n",
      "Test Dataset Shape: (418, 11)\n",
      "Sex         0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "Sex         0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "Taille de X_train : (712, 8)\n",
      "Taille de X_test : (179, 8)\n",
      "Taille de Y_train : (712,)\n",
      "Taille de Y_test : (179,)\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Macro F1 Score (Gradient Boosting): 0.7930772533606367\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "14c9b4cd3aec12b8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
